---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

**About Me**

I'm a Research Scientist at [Snap Research](https://research.snap.com/) on the [User Modeling and Personalization (UMaP)](https://research.snap.com/team/user-modeling-and-personalization.html) team led by [Neil Shah](https://nshah.net/). My research focuses on user representation learning from sequential and multi-modal interaction data. 

I completed my PhD at UT Austin, where I was advised by [Aryan Mokhtari](https://sites.utexas.edu/mokhtari/) and [Sanjay Shakkottai](https://sites.google.com/view/sanjay-shakkottai/home) and studied in-context learning, multi-task learning and feature learning theory, among other ML theory topics. Prior to this I earned a B.S.E. from Princeton where I worked under [Yuxin Chen](https://yuxinchen2020.github.io/).

My email is lcollins2 at snap dot com.

**We are currently recruiting interns to work on a variety of projects in recommendation, user modeling and graph learning for 2026. Start dates are flexible. If interested please send me an email, job link to appear soon.**

[Last update: November 2025]
<!---
My CV can be found [here](https://liamc2196.github.io/files/Liamc_CV_nov22.pdf) (updated 11/2022).
--->

## News

- **October 2025** Our paper ["Generative Recommendation with Semantic IDs: A Practitioner's Handbook"](https://arxiv.org/abs/2507.22224) won the Best Paper Award at CIKM 2025! Please take a look at our [public repo](https://github.com/snap-research/GRID), and see you in Seoul!

- **October 2025** Our paper studying [data augmentation for generative recommendation](https://arxiv.org/abs/2509.13648) has been accepted to WSDM 2025. Congrats to [Geon](https://geonlee0325.github.io/)! See you in Boise.

- **October 2025** We recently released a pre-print studying the [scaling laws of generative recommendation](https://arxiv.org/pdf/2509.25522)! Please take a look and suggestions are welcomed.

- **September 2025** Our paper on [meta-learning for LoRA](https://arxiv.org/abs/2410.22264) was accepted to NeurIPS 2025. Congrats to [Jacob](https://jacob-block.github.io/) and [Sundar](https://sundararajan-s.github.io/)! See you in sunny San Diego.

- **May 2025** Two of our papers are accepted to the research track at KDD 2025. One studies the [popularity bias of recommender systems](https://arxiv.org/abs/2505.11318) and the other studies [cross-domain sequential recommendation](https://arxiv.org/abs/2505.21811).

- **April 2025** Our paper studying [universal user representation learning](https://arxiv.org/abs/2504.21838) via cross-domain user signals has been accepted to the industry track at SIGIR 2025.

- **November 2024** Selected as a top reviewer for NeurIPS 2024.

- **September 2024:** Started working at Snap!

- **September 2024:** Our in-context learning [paper](https://www.arxiv.org/pdf/2402.11639.pdf) was selected for Spotlight Presentation at NeurIPS 2024.

- **June 2024:** Our multi-task learning [paper](https://arxiv.org/pdf/2307.06887.pdf) was selected for Oral Presentation at ICML 2024.

- **May 2024:** Our [paper](https://arxiv.org/pdf/2307.06887.pdf) on multi-task learning with two-layer ReLU networks was accepted at ICML 2024.

- **April 2024:** Defended my thesis! 

- **February 2024:** New [paper](https://arxiv.org/pdf/2402.11639.pdf) on in-context learning with transformers with softmax-activated self-attention.

- **December 2023:** Our [paper](https://arxiv.org/pdf/2310.04627.pdf) was selected as a Best Paper at [FL@FM-NeurIPS’23](https://federated-learning.org/fl@fm-neurips-2023/).

- **October 2023:** Our [paper](https://arxiv.org/pdf/2310.04627.pdf) on federated prompt tuning was selected for Oral Presentation at [FL@FM-NeurIPS’23](https://federated-learning.org/fl@fm-neurips-2023/).

- **Summer 2023:** I interned at Google Research, working with [Shanshan Wu](https://wushanshan.github.io/), [Sewoong Oh](https://homes.cs.washington.edu/~sewoong/), and [Khe Chai Sim](https://scholar.google.com/citations?user=jnU62sUAAAAJ&hl=en) on federated prompt tuning of large language models.

- **June 2023:** New [paper](https://arxiv.org/pdf/2307.06887.pdf) on multi-task learning with two-layer ReLU networks.

- **May 2023:** Our paper [InfoNCE Loss Provably Learns Cluster-Preserving Representations](https://arxiv.org/pdf/2302.07920.pdf) was accepted at COLT 2023.

- **October 2022:** I gave a [talk](https://sites.google.com/view/one-world-seminar-series-flow/archive/2022) on representation learning in federated learning at the Federated Learning One World (FLOW) Seminar.

- **Summer 2022:** I interned at Amazon Alexa under the supervision of [Jie Ding](https://jding.org/) and [Tanya Roosta](https://www.amazon.science/author/tanya-g-roosta). My project studied personalized federated learning with side information. Our [paper](https://openreview.net/forum?id=HRZjvFkX-faD) was accepted at [FL-NeurIPS'22](https://federated-learning.org/fl-neurips-2022/). 



<!---{% for post in site.publications reversed %}
          {% include archive-single.html %}
     {% endfor %}--->



## Papers

Please see my [Google Scholar profile](https://scholar.google.com/citations?user=MRLe02cAAAAJ&hl=en) for the most updated list of papers.


**In-Context Learning with Transformers: Softmax Attention Adapts to Function Lipschitzness**  
*LC\*, Advait Parulekar\*, Aryan Mokhtari, Sujay Sanghavi, Sanjay Shakkottai*  
\* co-first authors  
NeurIPS 2024, Spotlight
[\[PDF\]](https://arxiv.org/pdf/2402.11639)

**Provable Multi-Task Representation Learning by Two-Layer ReLU Neural Networks**  
*LC, Hamed Hassani, Mahdi Soltanolkotabi, Aryan Mokhtari, Sanjay Shakkottai*  
ICML 2024 **Oral Presentation**
[\[PDF\]](https://arxiv.org/pdf/2307.06887.pdf)

**Profit: Benchmarking Personalization and Robustness Trade-off in Federated Prompt Tuning**  
*LC, Shanshan Wu, Sewoong Oh, Khe Chai Sim*  
Workshop on Federated Learning in the Age of Foundation Models in Conjunction with NeurIPS 2023  **Best Paper**  
[\[PDF\]](https://arxiv.org/pdf/2310.04627.pdf) 

**InfoNCE Provably Learns Cluster-Preserving Representations**  
*Advait Parulekar, LC, Karthikeyan Shanmugam, Aryan Mokhtari, Sanjay Shakkottai*  
COLT 2023  
[\[PDF\]](https://arxiv.org/pdf/2302.07920.pdf)

**FedAvg with Fine-Tuning: Local Updates Lead to Representation Learning**  
*LC, Hamed Hassani, Aryan Mokhtari, Sanjay Shakkottai*  
NeurIPS 2022     
[\[PDF\]](https://arxiv.org/pdf/2205.13692.pdf)

**PerFedSI: A Framework for Personalized Federated Learning with Side Information**  
*LC, Enmao Diao, Tanya Roosta, Jie Ding, Tao Zhang*  
Workshop on Federated Learning: Recent Advances and New Challenges in Conjunction with NeurIPS 2022  
[\[PDF\]](https://openreview.net/pdf?id=HRZjvFkX-faD) 

**MAML and ANIL Provably Learn Representations**  
*LC, Aryan Mokhtari, Sewoong Oh, Sanjay Shakkottai*  
ICML 2022     
[\[PDF\]](https://arxiv.org/pdf/2202.03483.pdf)

**How does the Task Landscape Affect MAML Performance?**  
*LC, Aryan Mokhtari, Sanjay Shakkottai*  
CoLLAs 2022 *Oral Presentation*   
[\[PDF\]](https://arxiv.org/pdf/2010.14672.pdf)

**Exploiting Shared Representations for Personalized Federated
Learning**  
*LC, Hamed Hassani, Aryan Mokhtari, Sanjay Shakkottai*  
ICML 2021    
[\[PDF\]](https://arxiv.org/pdf/2102.07078.pdf) [\[Code\]](https://github.com/lgcollins/FedRep)

**Task-Robust Model-Agnostic Meta-Learning**  
*LC, Aryan Mokhtari, Sanjay Shakkottai*  
NeurIPS 2020    
[\[PDF\]](https://arxiv.org/abs/2002.04766.pdf) [\[Code\]](https://github.com/lgcollins/tr-maml)
